package HFR;

use 5.012003;
use strict;
use warnings;
use diagnostics;

use PDL;
use PDL::NiceSlice;
use PDL::Constants;
#use PDL::Slatec;
use Date::Calc qw(:all);

require Exporter;
our @ISA = qw(Exporter);

# Items to export into callers namespace by default. Note: do not export
# names by default without a very good reason. Use EXPORT_OK instead.
# Do not simply export all your public functions/methods/constants.

# This allows declaration	use HFR ':all';
# If you do not need this, moving things directly into @EXPORT or @EXPORT_OK
# will save memory.
our %EXPORT_TAGS = ( 'all' => [ qw(
	
) ] );

our @EXPORT_OK = ( @{ $EXPORT_TAGS{'all'} } );

our @EXPORT = qw(
	
);

our $VERSION = '0.01';

##########################################################################
# SUBROUTINES/METHODS
##########################################################################

=head1 SUBROUTINES/METHODS

=head2 def_t

=cut

sub define_time { #input string = "yyyy-mm-dd HH:MM"
    my ($DATE,$TIME) = split( '\s+' , $_[0] );
    my ($YR,$MO,$MD) = split( '-' , $DATE );
    my ($HR,$MN)     = split( ':' , $TIME );
    my $TS           = Mktime($YR,$MO,$MD,$HR,$MN,"0");
    return $TS;
}

=head2 distance

=cut

sub distance {

    # This subroutine will compute the distances between two pairs of lon/lat points
    # and return the results as a pair of values in metres east and north from
    # the first point. The equation was extracted from Bowditch's book ``The American
    # Practical Navigator'', 1995, page 552
    my $class = {};
    my $ln0 = shift;
    my $lt0 = shift;
    my $ln1 = shift; 
    my $lt1 = shift;

    my $lt0_rad = ($lt0*PI)/180; #radian conversion
    my $y = (111132.92-559.82)*cos(2*$lt0_rad) + 1.175*cos(4*$lt0_rad) - 0.0023*cos(6*$lt0_rad);
    my $x = 111412.84*cos($lt0_rad) - 93.5*cos(3*$lt0_rad) + 0.0118*cos(5*$lt0_rad);
    my $e = ($ln1-$ln0) * $x;
    my $n = ($lt1-$lt0) * $y;
    my $d = sqrt( $e**2 + $n**2 ) / 1.0e4;
    bless $class , $d; 
    return($d);

  }

=head2 peak_rayleigh

=cut

sub peak_rayleigh {

    my $class = {};
    my $pwr = shift;

    my $n_coefs = 7;
    my $n_bins = 20; #alternative method: $n_bins = MATLAB_CODE< length( min(pwr) : (min(pwr)/max(pwr)) : max(pwr) ) >
    my $confidence_interval_95 = 7.77;

    # POLYNOMICAL CALCULATION CRITERION
    # specifies the criterion to be used in determining the degree of fit to be computed.
    # (1)  If  EPS  is input negative,  POLFIT  chooses the
    #    degree based on a statistical F test of
    #    significance.  One of three possible
    #    significance levels will be used:  .01, .05 or
    #    .10.  If  EPS=-1.0 , the routine will
    #    automatically select one of these levels based
    #    on the number of data points and the maximum
    #    degree to be considered.  If  EPS  is input as
    #    -.01, -.05, or -.10, a significance level of
    #    .01, .05, or .10, respectively, will be used.
    # (2)  If  EPS  is set to 0.,  POLFIT  computes the
    #    polynomials of degrees 0 through  MAXDEG .
    # (3)  If  EPS  is input positive,  EPS  is the RMS
    #    error tolerance which must be satisfied by the
    #    fitted polynomial.  POLFIT  will increase the
    #    degree of fit until this criterion is met or
    #    until the maximum degree is reached.C
    my $poly_criterion = 0; 

    # POLYFIT
    # Use the coefficients generated by POLFIT to evaluate the
    #    polynomial fit of degree L, along with the first NDER of
    #    its derivatives, at a specified point.
    #  Input --
    #      L -      the degree of polynomial to be evaluated.  L  may be
    #               any non-negative integer which is less than or equal
    #               to  NDEG , the highest degree polynomial provided
    #               by  POLFIT .
    #      NDER -   the number of derivatives to be evaluated.  NDER
    #               may be 0 or any positive value.  If NDER is less
    #               than 0, it will be treated as 0.
    #      X -      the argument at which the polynomial and its
    #               derivatives are to be evaluated.
    #      A -      work and output array containing values from last
    #               call to  POLFIT .
    my $nder = 1;

    my $pwr_rng = zeros(abs(($pwr->max)-($pwr->min)),1)->xlinvals($pwr->min,$pwr->max);
    my($bin_centres,$n_pwr) = hist( $pwr , $pwr->min , $pwr->max , abs($pwr->max - $pwr->min)/$n_bins );

    # compute weighs for polynomial fit and the fit the data to the polynomial, then extract the polynomial values
    my $pwr_weights = 1.0/$bin_centres**2;
    my($ndeg,$jk0,$jk1,$pfit_coefs) = polyfit($n_pwr,$bin_centres,$pwr_weights,$n_coefs,$poly_criterion); undef $jk0; undef $jk1;
    my $pwr_coefs = polyvalue($n_coefs,$nder,$pwr_rng,$pfit_coefs);

    # using the index of the maximum power determine the theshold for the regions
    my($min_pwr_coefs,$max_pwr_coefs,$minI_pwr_coefs,$maxI_pwr_coefs) = minmaximum($pwr_coefs);
    my $pwr_thresh = ($pwr_rng($maxI_pwr_coefs) + $confidence_interval_95)->max;
    bless $class , $pwr_thresh;
    return($pwr_thresh);

}

=head2 vector_data_extract

=cut

sub vector_data_extract {

  my $class = {};

  my ($vars,$nc,$STA) = @_;
  my @VARS       = @$vars;
  my($S,$D,$U,$V,$LN,$LT,$ln,$lt);

  # loop over each variable to extract
  foreach my $l2 (@VARS) {

    if ($l2 eq 'ssr_Surface_Eastward_Sea_Water_Velocity' or $l2 eq 'UCUR') {
      $U = $nc->get($l2);
      $U = $U->reshape;
      $U->badvalue(9999);
      $U->badflag(1);
      $U->inplace->setbadtonan;
    } elsif ($l2 eq 'ssr_Surface_Northward_Sea_Water_Velocity' or $l2 eq 'VCUR') {
      $V = $nc->get($l2);
      $V = $V-reshape();
      $V->badvalue(9999);
      $V->badflag(1);
      $V->inplace->setbadtonan;
    } elsif ($l2 eq 'LONGITUDE') {
      $ln = $nc->get($l2);
    } elsif ($l2 eq 'LATITUDE') {
      $lt = $nc->get($l2);
    }
  }

  # convert u and v to speed and direction
  $S = sqrt( $U**2 + $V**2 );
  $D = ((180/PI)*(atan2($V,$U))) % 360;

  # get lon lat into same dims as speed and direction
  if ( grep($_ eq $STA,("sag","rot","cbg","cof")) ) { #NEED TO CHANGE THIS IN THE FUTURE
    $LN  = $ln->(:,*$lt->nelem);
    $LT  = $lt->(*$ln->nelem,:);
  }

  bless $class, $LN;
  bless $class, $LT;
  bless $class, $D;
  bless $class, $S;

  return($LN,$LT,$D,$S);

}

#############################################################################

1;
__END__
# Below is stub documentation for your module. You'd better edit it!

=head1 NAME

HFR - Perl extension for high frequency oceanographic radar data

=head1 SYNOPSIS

  use HFR;

=head1 DESCRIPTION

At present this will serve as notes on the direction of HFR module.
There are a few subroutines at present:

def_t : which takes a string input of yyyy-mm-dd HH:MM and returns a Date::Calc->Mktime result

distance : which takes in two geographic points and returns the straigth line distance between them

peak_rayliegh : computes the maximum spectrum power for a given range of power

vector_data_extract : extract vector data from a netcdf file on the qcif server

Listen, all of this is fine-and-dandy, but I really need to move away from this.  Here is what I would like to build:

$nc = HFR::ACORN::NetCDF->new( ssh => "<user>@<server>:<full_path_to_netcdf> )
or
$nc = HFR::ACORN::NetCDF->new( url => "<full_url_path_to_netcdf> )

These modules would need to be run first to generate the filename or list of filenames

$url = HFR::QCIF->new( name => "Cape Wiles" , time => "2010-10-12 12:00" , qc => 1 )
or
@url = HFR::QCIF->new( name => "Spencer" , time_start => "2010-10-12 12:00" , time_stop => "2011-10-12 23:00" , qc => 1 )

OR

$ssh = HFR::SSH->new( user => "codar" , server => "acorn" , name => "Cape Wiles" , time => "2010-10-12 12:00" , qc => 1 )
or
@ssh = HFR::SSH->new( user => "codar" , server => "acorn" , name => "Spencer" , time_start => "2010-10-12 12:00" , time_stop => "2011-10-12 23:00" , qc => 1 )

AND

Create new and load default parameters for a site or station
%params = HFR::Analysis::Parameters->load( site => "South Australian Gulf" ); *this will contain grid and mask information as well as standard parameters for site*
%params = HFR::Analysis::Parameters->amend( site => "SAG" , temporal_averaging => 86400 , temporal_gap_tolerance => 3600 , spatial_gap_tolerance => 5 , spatial_gap_units => "km" );
$vec = HFR::Analysis::Vectors->( stations => @station_names , configuration_parameters => %params , time_start => "2011-12-01" , time_stop => "now" , qc => 0 , write_date => 1 ); 
* the above sequence would load /SAG/ parameters, make an amendment to parameters so that 24 hour averages are made with an hour as maximum gap tolerance to average acrossxfb

---------------------------------------------------------
*There is also the potential for the following:
$inv = HFR::ACORN::Inventory->new;
$inv->list("Cape Wiles") or $inv->list("Wiles") or $inv->list("cwi") of which any of these would return a complete list of the inventory items at that station
or
$inv = HFR::ACORN::Inventory->new( station => "Spencer"); #create new MySQL table for station
$inv->add_item( name => "12 inch spanner" , condition => "rusty" );
$inv->add_item( name => "WERA RTU" , serial_no => "12312378" , photo => "wera_rack_rtu_cwi.png" , condition => "original" );

---------------------------------------------------------
Visualisation is another potential of the toolbox
$fig = HFR::Plot::Coverage->new( @nc_filenames );
or
$fig = HFR::Plot::Vectors->new( 


=head2 EXPORT

None by default.

=head1 SEE ALSO

packages used:
Date::Calc
PDL
PDL::NetCDF
PDL::Slatec
PDL::NiceSllice

Mention other useful documentation such as the documentation of
related modules or operating system documentation (such as man pages
in UNIX), or any relevant external documentation such as RFCs or
standards.

If you have a mailing list set up for your module, mention it here.

If you have a web site set up for your module, mention it here.

=head1 AUTHOR

Daniel Atwater, E<lt>danielpath2o@gmail.comE<gt>

=head1 COPYRIGHT AND LICENSE

Copyright (C) 2008 by Daniel Patrick Lewis Atwater

This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself, either Perl version 5.12.3 or,
at your option, any later version of Perl 5 you may have available.


=cut
